{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_cleanup\\\\data_test\\\\Cleaned\\\\cleanedup_by_Majid.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m     save_to_csv(data_final, output_file_path)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# فراخوانی تابع اصلی\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 77\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m data_final \u001b[38;5;241m=\u001b[39m clean_locality_names_column(data_final)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# 5. حذف ردیف‌ها با 'online sale' یا 'public sale' در 'Sale type' با استفاده از متد isin pandas\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m#data_final = remove_sale_type(data_final)\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# 6. ذخیره DataFrame تمیز شده به یک فایل CSV جدید با استفاده از متد to_csv pandas\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[43msave_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 49\u001b[0m, in \u001b[0;36msave_to_csv\u001b[1;34m(data, output_path)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_to_csv\u001b[39m(data, output_path):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# اینجا از متد to_csv در pandas برای ذخیره DataFrame به یک فایل CSV استفاده شده است\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\becod\\AI\\GNT-Arai-7\\01-TheField\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\becod\\AI\\GNT-Arai-7\\01-TheField\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\becod\\AI\\GNT-Arai-7\\01-TheField\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\becod\\AI\\GNT-Arai-7\\01-TheField\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\becod\\AI\\GNT-Arai-7\\01-TheField\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_cleanup\\\\data_test\\\\Cleaned\\\\cleanedup_by_Majid.csv'"
     ]
    }
   ],
   "source": [
    "# cleanind data\n",
    "# __________________________________________________________________________\n",
    "\n",
    "\n",
    "def read_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# __________________________________________________________________________\n",
    "\n",
    "# 1. remove dublicated rows\n",
    "def remove_duplicates(data):\n",
    "    return data.drop_duplicates()\n",
    "\n",
    "# 2. remove same Property IDs with different value\n",
    "def remove_duplicate_properties(data):\n",
    "    # اینجا از متد groupby و filter در pandas برای پیدا کردن 'Property ID' های تکراری استفاده شده است\n",
    "    # همچنین از isin و ایندکس‌گذاری pandas برای فیلتر کردن DataFrame استفاده شده است\n",
    "    duplicate_properties = data.groupby('Property ID').filter(lambda x: len(x) > 1)\n",
    "    return data[~data['Property ID'].isin(duplicate_properties['Property ID'])]\n",
    "\n",
    "# 3.1. پاکسازی ستون 'Locality name' با حذف کاراکترهای اضافی\n",
    "def clean_locality_name(name):\n",
    "    # اینجا از pandas به طور مستقیم استفاده نشده است، اما این تابع بعداً بر روی یک ستون pandas اعمال می‌شود\n",
    "    name = name.replace('%C', 'e')               # جایگزینی %C با e (اصالتاً è بود)\n",
    "    name = name.replace('%27', \"'\")              # جایگزینی %27 با '\n",
    "    name = name.replace('%20', ' ')              # جایگزینی %20 با فاصله\n",
    "    name = re.sub(r'%20%28.*?%29', '', name)     # حذف کاراکترها بین %20%28 و %29\n",
    "    name = re.sub(r'[0-9\\(\\)%]', '', name)       # حذف هر عدد و کاراکترهای خاص مانند پرانتز و %\n",
    "    name = re.sub(r'-\\d+$', '', name)            # حذف اعداد و - اگر نام شهر با (-عدد) تمام شود\n",
    "    name = name.lower().title()                  # تبدیل به حروف کوچک و سپس بزرگ کردن اولین حرف هر کلمه\n",
    "    return name.strip()                          # حذف فاصله‌های اضافی\n",
    "\n",
    "# 3.2. اعمال تابع پاکسازی بر روی ستون 'Locality name' در دیتاست\n",
    "def clean_locality_names_column(df):\n",
    "    # اینجا از متد apply در pandas برای اعمال تابع پاکسازی بر روی ستون 'Locality name' استفاده شده است\n",
    "    df['Locality'] = df['Locality'].apply(clean_locality_name)\n",
    "    return df\n",
    "\n",
    "# 4. حذف ردیف‌ها اگر مقدار 'Sale type' برابر با 'online sale' یا 'public sale' باشد\n",
    "# def remove_sale_type(data):\n",
    "#     # اینجا از متد isin در pandas برای فیلتر کردن ردیف‌هایی که 'Sale type' برابر با 'online sale' یا 'public sale' است استفاده شده است\n",
    "#     return data[~data['Sale type'].isin(['online sale', 'public sale'])]\n",
    "\n",
    "# __________________________________________________________________________\n",
    "\n",
    "# ذخیره کردن DataFrame تمیز شده در یک فایل CSV\n",
    "def save_to_csv(data, output_path):\n",
    "    # اینجا از متد to_csv در pandas برای ذخیره DataFrame به یک فایل CSV استفاده شده است\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "# __________________________________________________________________________\n",
    "\n",
    "# تابع اصلی برای مدیریت فرآیند تمیزکاری\n",
    "def main():\n",
    "    file_path = 'C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_cleanup\\\\data_test\\\\Details\\\\filtered_data_residential.csv'\n",
    "    output_file_path = 'C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_cleanup\\\\data_test\\\\Cleaned\\\\cleanedup_by_Majid.csv'\n",
    "    \n",
    "    # 1. خواندن فایل CSV به یک DataFrame\n",
    "    # از متد read_csv pandas استفاده شده است\n",
    "    data = read_csv(file_path)\n",
    "    \n",
    "    # 2. حذف ردیف‌های تکراری با استفاده از متد drop_duplicates pandas\n",
    "\n",
    "    data_cleaned = remove_duplicates(data)\n",
    "    \n",
    "    # 3. حذف املاک با 'Property ID' تکراری اما مقادیر متفاوت با استفاده از متد groupby، filter، isin و فیلتر کردن در pandas\n",
    "    data_final = remove_duplicate_properties(data_cleaned)\n",
    "    \n",
    "    # 4. پاکسازی ستون 'Locality name' با اعمال تابع تمیزسازی با استفاده از متد apply pandas\n",
    "    data_final = clean_locality_names_column(data_final)\n",
    "\n",
    "    # 5. حذف ردیف‌ها با 'online sale' یا 'public sale' در 'Sale type' با استفاده از متد isin pandas\n",
    "    #data_final = remove_sale_type(data_final)\n",
    "    \n",
    "    # 6. ذخیره DataFrame تمیز شده به یک فایل CSV جدید با استفاده از متد to_csv pandas\n",
    "    save_to_csv(data_final, output_file_path)\n",
    "\n",
    "# فراخوانی تابع اصلی\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\becod\\AI\\my-projects\\Majid_immoeliza_cleanup\\data_test\\Cleaned\\cleanedup_by_Majid.csv\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "# __________________________________________________________________________\n",
    "\n",
    "# Reading CSV file\n",
    "def read_csv(file_path):\n",
    "    # pandas is used here to read the CSV file and load it into a DataFrame\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# __________________________________________________________________________\n",
    "\n",
    "# 1. Remove duplicated rows\n",
    "def remove_duplicates(data):\n",
    "    # pandas method 'drop_duplicates' is used here to remove duplicated rows from the DataFrame\n",
    "    return data.drop_duplicates()\n",
    "\n",
    "# 2. Remove properties with same 'Property ID' but different values\n",
    "def remove_duplicate_properties(data):\n",
    "    # pandas groupby and filter methods are used here to find repeated 'Property ID's\n",
    "    # Also, isin and pandas indexing are used to filter the DataFrame\n",
    "    duplicate_properties = data.groupby('Property ID').filter(lambda x: len(x) > 1)\n",
    "    return data[~data['Property ID'].isin(duplicate_properties['Property ID'])]\n",
    "\n",
    "# 3.1. Clean 'Locality' column by removing extra characters\n",
    "def clean_locality_name(name):\n",
    "    # pandas is not directly used here, but this function will be applied later to a pandas column\n",
    "    name = name.replace('%C', 'e')               # replace %C with e (originally è)\n",
    "    name = name.replace('%27', \"'\")              # replace %27 with '\n",
    "    name = name.replace('%20', ' ')              # replace %20 with a space\n",
    "    name = re.sub(r'%20%28.*?%29', '', name)     # remove characters between %20%28 and %29\n",
    "    name = re.sub(r'[0-9\\(\\)%]', '', name)       # remove any numbers and special characters like parentheses and %\n",
    "    name = re.sub(r'-\\d+$', '', name)            # remove numbers and - if a city name ends with (-number)\n",
    "    name = name.lower().title()                  # convert to lowercase and capitalize the first letter of each word\n",
    "    return name.strip()                          # remove any extra spaces\n",
    "\n",
    "# 3.2. Apply the cleaning function to the 'Locality' column in the dataset\n",
    "def clean_locality_names_column(df):\n",
    "    # pandas apply method is used here to apply the cleaning function to the 'Locality' column\n",
    "    df['Locality'] = df['Locality'].apply(clean_locality_name)\n",
    "    return df\n",
    "\n",
    "# 4. Remove rows if 'Sale type' is 'online sale' or 'public sale'\n",
    "# def remove_sale_type(data):\n",
    "#     # pandas isin method is used here to filter rows where 'Sale type' is 'online sale' or 'public sale'\n",
    "#     return data[~data['Sale type'].isin(['online sale', 'public sale'])]\n",
    "\n",
    "# __________________________________________________________________________\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "def save_to_csv(data, output_path):\n",
    "    # pandas to_csv method is used here to save the DataFrame into a CSV file\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "# __________________________________________________________________________\n",
    "\n",
    "# Main function to manage the cleaning process\n",
    "def main():\n",
    "    file_path = 'C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_cleanup\\\\data_test\\\\Details\\\\filtered_data_residential.csv'\n",
    "    output_file_path = 'C:\\\\Users\\\\becod\\\\AI\\\\my-projects\\\\Majid_immoeliza_cleanup\\\\data_test\\\\Cleaned\\\\cleanedup_by_Majid.csv'\n",
    "    \n",
    "    # 1. Read the CSV file into a DataFrame\n",
    "    # pandas 'read_csv' method is used here\n",
    "    data = read_csv(file_path)\n",
    "    \n",
    "    # 2. Remove duplicated rows using pandas 'drop_duplicates' method\n",
    "    data_cleaned = remove_duplicates(data)\n",
    "    \n",
    "    # 3. Remove properties with duplicated 'Property ID' but different values using pandas groupby, filter, isin, and filtering\n",
    "    data_final = remove_duplicate_properties(data_cleaned)\n",
    "    \n",
    "    # 4. Clean the 'Locality' column by applying the cleaning function using pandas 'apply' method\n",
    "    data_final = clean_locality_names_column(data_final)\n",
    "\n",
    "    # 5. Remove rows with 'online sale' or 'public sale' in 'Sale type' using pandas 'isin' method\n",
    "    #data_final = remove_sale_type(data_final)\n",
    "    \n",
    "    # 6. Save the cleaned DataFrame to a new CSV file using pandas 'to_csv' method\n",
    "    save_to_csv(data_final, output_file_path)\n",
    "\n",
    "# Call the main function\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
